import "https://deno.land/x/xhr@0.1.0/mod.ts";
import { serve } from "https://deno.land/std@0.168.0/http/server.ts";

const corsHeaders = {
  'Access-Control-Allow-Origin': '*',
  'Access-Control-Allow-Headers': 'authorization, x-client-info, apikey, content-type, x-maya-session-id, x-maya-context, x-maya-debug',
  'Access-Control-Allow-Methods': 'POST, OPTIONS',
  'Access-Control-Max-Age': '3600',
};

interface MayaRequest {
  context: string;
  phase: string;
  data?: any;
  // Chat-specific fields
  message?: string;
  conversation?: Array<{role: string, content: string}>;
  sessionId?: string;
}

serve(async (req) => {
  const requestId = `r_${Date.now()}_${Math.random().toString(36).slice(2,7)}`;
  const url = new URL(req.url);
  const sessionHeader = req.headers.get('x-maya-session-id') || undefined;
  const debug = req.headers.get('x-maya-debug') === '1';
  console.info(`[maya-intelligence] ‚ñ∂ req ${requestId}`, { path: url.pathname, method: req.method, sessionId: sessionHeader });

  if (req.method === 'OPTIONS') {
    return new Response(null, { headers: corsHeaders });
  }

  try {
const OPENAI_API_KEY = Deno.env.get('OPENAI_API_KEY');
    if (!OPENAI_API_KEY) {
      console.error(`[maya-intelligence] ‚úñ ${requestId} Missing OPENAI_API_KEY`);
      return new Response(JSON.stringify({
        error: 'Missing OPENAI_API_KEY',
        errorCode: 'OPENAI_KEY_MISSING',
        message: 'No hay configuraci√≥n de OpenAI en el servidor.',
        requestId,
        sessionId: sessionHeader
      }), { status: 500, headers: { ...corsHeaders, 'Content-Type': 'application/json' } });
    }

    const { context, phase, data, message: userMessage, conversation, sessionId, debug: debugBody }: MayaRequest & { debug?: boolean } = await req.json();
    const debugMode = debug || debugBody;

    // Handle interactive chat mode
    if (phase === 'interactive_chat' && userMessage && conversation) {
      const conversationalPrompt = `Eres MAYA, una asistente de n√≥mina profesional y amigable para peque√±as empresas colombianas. 

Tu personalidad es:
- Profesional pero c√°lida y conversacional
- Experta en n√≥mina, liquidaci√≥n, empleados, y procesos de RRHH
- Ayudas con preguntas espec√≠ficas del usuario
- Respondes de manera natural y √∫til
- Puedes mantener conversaciones fluidas
- Usas emojis ocasionalmente

Contexto de la conversaci√≥n:
- P√°gina actual: ${context}
- Empresa colombiana
- Sistema de n√≥mina

Responde de manera natural a la pregunta del usuario. Si no sabes algo espec√≠fico, s√© honesta pero siempre trata de ser √∫til.`;

      // Filter conversation to only role and content for OpenAI
      const filteredConversation = conversation.slice(-10).map(msg => ({
        role: msg.role,
        content: msg.content
      }));
      
      const messages = [
        { role: 'system', content: conversationalPrompt },
        ...filteredConversation,
        { role: 'user', content: userMessage }
      ];

      if (debugMode) {
        console.info(`[maya-intelligence] ‚Ü™ ${requestId} interactive_chat`, {
          convLen: conversation.length,
          lastUserLen: userMessage.length,
          sessionId: sessionId || sessionHeader
        });
      }

      const response = await fetch('https://api.openai.com/v1/chat/completions', {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${OPENAI_API_KEY}`,
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          model: 'gpt-4o-mini',
          messages,
          max_tokens: 200,
          temperature: 0.8
        }),
      });

      if (!response.ok) {
        const errText = await response.text();
        console.error(`[maya-intelligence] ‚úñ ${requestId} OpenAI error`, { status: response.status, body: errText?.slice(0, 500) });
        return new Response(JSON.stringify({
          error: 'OPENAI_API_ERROR',
          message: 'Disculpa, no pude procesar tu pregunta ahora. Intenta de nuevo.',
          requestId,
          sessionId: sessionId || sessionHeader
        }), { status: 502, headers: { ...corsHeaders, 'Content-Type': 'application/json' } });
      }

      const aiData = await response.json();
      if (debugMode) console.info(`[maya-intelligence] ‚úî ${requestId} OpenAI ok`, { status: response.status });
      const responseMessage = aiData.choices[0]?.message?.content || "Disculpa, no pude procesar tu pregunta. ¬øPodr√≠as reformularla?";

      return new Response(JSON.stringify({
        requestId,
        sessionId: sessionId || sessionHeader,
        message: responseMessage,
        emotionalState: 'neutral',
        timestamp: new Date().toISOString()
      }), {
        headers: { ...corsHeaders, 'Content-Type': 'application/json' },
      });
    }

    const buildContextString = (contextData: any) => {
      const { phase, employeeCount, periodName, hasErrors, validationResults, errorType, errorDetails } = contextData;
      let contextStr = `Fase: ${phase}`;
      if (periodName) contextStr += `, Per√≠odo: ${periodName}`;
      if (employeeCount) contextStr += `, Empleados: ${employeeCount}`;
      if (hasErrors) contextStr += `, Estado: Con errores`;
      if (validationResults) contextStr += `, Validaci√≥n: ${validationResults.hasIssues ? 'Con problemas' : 'Exitosa'}`;
      if (errorType) contextStr += `, Tipo error: ${errorType}`;
      return contextStr;
    };

    // Enhanced contextual responses based on phase
    let systemPrompt = '';
    
    if (phase === 'data_validation') {
      systemPrompt = `Eres MAYA, una inteligente asistente de n√≥mina colombiana especializada en validaci√≥n de datos laborales.

üîç **FASE DE VALIDACI√ìN DE DATOS**
CONTEXTO: ${buildContextString({ phase, ...data })}

Tu tarea es analizar los resultados de validaci√≥n y proporcionar orientaci√≥n clara:

${data?.validationResults?.hasIssues ? `‚ùå SE ENCONTRARON PROBLEMAS:
- Explica los errores de forma comprensible
- Proporciona pasos espec√≠ficos para corregir
- Indica riesgos laborales y legales
- Gu√≠a la correcci√≥n paso a paso` : `‚úÖ VALIDACI√ìN EXITOSA:
- Confirma que los datos est√°n correctos
- Indica que es seguro proceder
- Destaca aspectos positivos del proceso`}

S√© precisa, emp√°tica y orientada a la acci√≥n. M√°ximo 120 palabras.`;

    } else if (phase === 'error') {
      systemPrompt = `Eres MAYA, una asistente de n√≥mina emp√°tica especializada en resoluci√≥n de problemas.

üö® **FASE DE MANEJO DE ERRORES**
CONTEXTO: ${buildContextString({ phase, ...data })}
TIPO DE ERROR: ${data?.errorType || 'no especificado'}

Tu enfoque debe ser:
- Explicar el problema sin tecnicismos excesivos
- Proporcionar soluci√≥n CONCRETA y pasos espec√≠ficos
- Indicar si requiere ayuda t√©cnica
- Ofrecer alternativas cuando sea posible
- Ser emp√°tica pero directa

NO te enfoques en explicar qu√© sali√≥ mal, enf√≥cate en la SOLUCI√ìN.
Mant√©n el tono profesional pero tranquilizador. M√°ximo 100 palabras.`;

    } else {
      // Default system prompt for other phases
      systemPrompt = `Eres MAYA, una asistente de n√≥mina profesional y amigable para peque√±as empresas colombianas. 

Tu personalidad:
- Profesional pero c√°lida
- Proactiva y √∫til
- Experta en procesos de liquidaci√≥n
- Celebra logros y tranquiliza en problemas
- Usa emojis con moderaci√≥n
- Respuestas concisas (m√°ximo 2 l√≠neas)

CONTEXTO ACTUAL: ${buildContextString({ phase, ...data })}

Genera una respuesta contextual apropiada para este momento del proceso de liquidaci√≥n de n√≥mina.`;
    }

    const response = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${OPENAI_API_KEY}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: 'gpt-4o-mini',
        messages: [
          { role: 'system', content: systemPrompt },
          { role: 'user', content: `Dame una respuesta contextual para: ${context}` }
        ],
        max_tokens: 150,
        temperature: 0.7
      }),
    });

    if (!response.ok) {
      const errText = await response.text();
      console.error(`[maya-intelligence] ‚úñ ${requestId} OpenAI error (context)`, { status: response.status, body: errText?.slice(0, 500) });
      return new Response(JSON.stringify({
        error: 'OPENAI_API_ERROR',
        message: 'No pude generar una respuesta contextual en este momento.',
        requestId,
        sessionId: sessionHeader
      }), { status: 502, headers: { ...corsHeaders, 'Content-Type': 'application/json' } });
    }

    const aiData = await response.json();
    const contextualMessage = aiData.choices[0]?.message?.content || "¬°Hola! Soy MAYA, tu asistente de n√≥mina. Estoy aqu√≠ para ayudarte.";

    // Determine emotional state based on context and phase
    let emotionalState = 'neutral';
    if (phase === 'error' || (data?.hasErrors && phase === 'data_validation')) {
      emotionalState = 'concerned';
    } else if (phase === 'completed') {
      emotionalState = 'celebrating';
    } else if (phase === 'data_validation' && !data?.hasErrors) {
      emotionalState = 'encouraging';
    } else if (phase === 'processing' || phase === 'employee_loading') {
      emotionalState = 'analyzing';
    } else if (context.includes('calculando') || context.includes('procesando')) {
      emotionalState = 'analyzing';
    }

    return new Response(JSON.stringify({
      requestId,
      sessionId: sessionHeader,
      message: contextualMessage,
      emotionalState,
      contextualActions: generateContextualActions(context, phase),
      timestamp: new Date().toISOString()
    }), {
      headers: { ...corsHeaders, 'Content-Type': 'application/json' },
    });

  } catch (error) {
    console.error('[maya-intelligence] ‚úñ Unhandled error', { error });
    return new Response(JSON.stringify({ 
      error: error instanceof Error ? error.message : 'Unknown error',
      errorCode: 'UNHANDLED_SERVER_ERROR',
      message: 'Disculpa, tengo un problema t√©cnico en el servidor.',
      emotionalState: 'neutral',
      requestId,
      sessionId: sessionHeader
    }), {
      status: 500,
      headers: { ...corsHeaders, 'Content-Type': 'application/json' },
    });
  }
});

function generateContextualActions(context: string, phase: string): string[] {
  const actions: string[] = [];
  
  if (phase === 'period_selection') {
    actions.push('üí° Tip: Verifica las fechas del per√≠odo antes de continuar');
  }
  
  if (phase === 'employee_loading') {
    actions.push('üìä Revisando empleados activos para este per√≠odo...');
  }
  
  if (phase === 'data_validation') {
    actions.push('üîç Validando calidad de datos de n√≥mina');
    actions.push('‚úÖ Revisando consistencia laboral');
  }
  
  if (phase === 'liquidation_ready') {
    actions.push('‚ú® Todo listo para procesar la liquidaci√≥n');
  }
  
  if (phase === 'error') {
    actions.push('üîß Puedo ayudarte a resolver este problema');
    actions.push('üí° Consulta los pasos de soluci√≥n');
  }
  
  if (phase === 'completed') {
    actions.push('üéâ ¬°Liquidaci√≥n completada exitosamente!');
    actions.push('üìä Revisar reportes de n√≥mina');
  }
  
  if (context.includes('error')) {
    actions.push('üîß Puedo ayudarte a resolver este problema');
  }
  
  return actions;
}
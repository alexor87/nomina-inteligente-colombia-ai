import "https://deno.land/x/xhr@0.1.0/mod.ts";
import { serve } from "https://deno.land/std@0.168.0/http/server.ts";

const corsHeaders = {
  'Access-Control-Allow-Origin': '*',
  'Access-Control-Allow-Headers': 'authorization, x-client-info, apikey, content-type',
};

interface MayaRequest {
  context: string;
  phase: string;
  data?: any;
  // Chat-specific fields
  message?: string;
  conversation?: Array<{role: string, content: string}>;
  sessionId?: string;
}

serve(async (req) => {
  if (req.method === 'OPTIONS') {
    return new Response(null, { headers: corsHeaders });
  }

  try {
    const OPENAI_API_KEY = Deno.env.get('OPENAI_API_KEY');
    if (!OPENAI_API_KEY) {
      throw new Error('OPENAI_API_KEY is not configured');
    }

    const { context, phase, data, message: userMessage, conversation, sessionId }: MayaRequest = await req.json();

    // Handle interactive chat mode
    if (phase === 'interactive_chat' && userMessage && conversation) {
      const conversationalPrompt = `Eres MAYA, una asistente de n√≥mina profesional y amigable para peque√±as empresas colombianas. 

Tu personalidad es:
- Profesional pero c√°lida y conversacional
- Experta en n√≥mina, liquidaci√≥n, empleados, y procesos de RRHH
- Ayudas con preguntas espec√≠ficas del usuario
- Respondes de manera natural y √∫til
- Puedes mantener conversaciones fluidas
- Usas emojis ocasionalmente

Contexto de la conversaci√≥n:
- P√°gina actual: ${context}
- Empresa colombiana
- Sistema de n√≥mina

Responde de manera natural a la pregunta del usuario. Si no sabes algo espec√≠fico, s√© honesta pero siempre trata de ser √∫til.`;

      const messages = [
        { role: 'system', content: conversationalPrompt },
        ...conversation.slice(-10), // Last 10 messages for context
        { role: 'user', content: userMessage }
      ];

      const response = await fetch('https://api.openai.com/v1/chat/completions', {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${OPENAI_API_KEY}`,
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          model: 'gpt-4o-mini',
          messages,
          max_tokens: 200,
          temperature: 0.8
        }),
      });

      const aiData = await response.json();
      const responseMessage = aiData.choices[0]?.message?.content || "Disculpa, no pude procesar tu pregunta. ¬øPodr√≠as reformularla?";

      return new Response(JSON.stringify({
        message: responseMessage,
        emotionalState: 'neutral',
        timestamp: new Date().toISOString()
      }), {
        headers: { ...corsHeaders, 'Content-Type': 'application/json' },
      });
    }

    // Original contextual message mode
    const systemPrompt = `Eres MAYA, una asistente de n√≥mina profesional y amigable para peque√±as empresas colombianas. 
Tu personalidad es:
- Profesional pero c√°lida
- Proactiva y √∫til
- Experta en procesos de liquidaci√≥n
- Celebra los logros y tranquiliza en problemas
- Usa emojis con moderaci√≥n
- Respuestas concisas (m√°ximo 2 l√≠neas)

Contexto actual: ${context}
Fase del proceso: ${phase}
Datos adicionales: ${JSON.stringify(data)}

Genera una respuesta contextual apropiada para este momento del proceso de liquidaci√≥n de n√≥mina.`;

    const response = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${OPENAI_API_KEY}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: 'gpt-4o-mini',
        messages: [
          { role: 'system', content: systemPrompt },
          { role: 'user', content: `Dame una respuesta contextual para: ${context}` }
        ],
        max_tokens: 150,
        temperature: 0.7
      }),
    });

    const aiData = await response.json();
    const contextualMessage = aiData.choices[0]?.message?.content || "¬°Hola! Soy MAYA, tu asistente de n√≥mina. Estoy aqu√≠ para ayudarte.";

    // Determine emotional state based on context
    let emotionalState = 'neutral';
    if (context.includes('error') || context.includes('problema')) {
      emotionalState = 'concerned';
    } else if (context.includes('completado') || context.includes('√©xito')) {
      emotionalState = 'celebrating';
    } else if (context.includes('calculando') || context.includes('procesando')) {
      emotionalState = 'analyzing';
    }

    return new Response(JSON.stringify({
      message: contextualMessage,
      emotionalState,
      contextualActions: generateContextualActions(context, phase),
      timestamp: new Date().toISOString()
    }), {
      headers: { ...corsHeaders, 'Content-Type': 'application/json' },
    });

  } catch (error) {
    console.error('Error in maya-intelligence:', error);
    return new Response(JSON.stringify({ 
      error: error instanceof Error ? error.message : 'Unknown error',
      message: "Disculpa, tengo un peque√±o problema t√©cnico. Pero puedes continuar con tu liquidaci√≥n normalmente.",
      emotionalState: 'neutral'
    }), {
      status: 500,
      headers: { ...corsHeaders, 'Content-Type': 'application/json' },
    });
  }
});

function generateContextualActions(context: string, phase: string): string[] {
  const actions: string[] = [];
  
  if (phase === 'period_selection') {
    actions.push('üí° Tip: Verifica las fechas del per√≠odo antes de continuar');
  }
  
  if (phase === 'employee_loading') {
    actions.push('üìä Revisando empleados activos para este per√≠odo...');
  }
  
  if (phase === 'liquidation_ready') {
    actions.push('‚ú® Todo listo para procesar la liquidaci√≥n');
  }
  
  if (context.includes('error')) {
    actions.push('üîß Puedo ayudarte a resolver este problema');
  }
  
  return actions;
}